{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install Libraries"
      ],
      "metadata": {
        "id": "bW5bQiMhhzoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pybaseball pandas numpy xgboost scikit-learn\n"
      ],
      "metadata": {
        "id": "jst7ifYBhx6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Libraries"
      ],
      "metadata": {
        "id": "Wercran3nAji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pybaseball import batting_stats\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "6QaeJC4hnCPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Pull 2010-2023 Batting Stats"
      ],
      "metadata": {
        "id": "k9nhbPnwhkpB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKWNjkmMg070"
      },
      "outputs": [],
      "source": [
        "# Get batting stats for multiple years (2015-2023)\n",
        "years = list(range(2015, 2024))\n",
        "batting_data = pd.concat([batting_stats(y) for y in years], ignore_index=True)\n",
        "\n",
        "# Select key batting metrics (adding new high-impact features)\n",
        "batting_features = [\n",
        "    \"IDfg\", \"Season\", \"wOBA\", \"xwOBA\", \"ISO+\", \"EV\", \"HardHit%\", \"WPA\", \"REW\", \"OBP\", \"SLG\", \"ISO\", \"Age\",\n",
        "    \"WPA/LI\", \"Off\", \"xSLG\", \"wRAA\", \"RE24\", \"maxEV\",  # Existing features\n",
        "    \"BB%\", \"K%\", \"Spd\"  # New features for feature engineering\n",
        "]\n",
        "\n",
        "# Keep only relevant columns\n",
        "batting_data = batting_data[batting_features]\n",
        "\n",
        "# Rename columns to match expected format\n",
        "batting_data.rename(columns={\n",
        "    \"IDfg\": \"player_id\",\n",
        "    \"Season\": \"year\",\n",
        "    \"HardHit%\": \"hard_hit_rate\",\n",
        "    \"maxEV\": \"max_exit_velocity\",\n",
        "    \"BB%\": \"bb_rate\",\n",
        "    \"K%\": \"k_rate\",\n",
        "    \"Spd\": \"speed_score\"\n",
        "}, inplace=True)\n",
        "\n",
        "# Ensure correct data types\n",
        "batting_data[\"year\"] = batting_data[\"year\"].astype(int)\n",
        "\n",
        "print(f\"✅ Pulled batting stats from {years[0]} to {years[-1]} (Statcast Era)\")\n",
        "print(f\"✅ Dataset Shape After Filtering: {batting_data.shape}\")\n",
        "print(batting_data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Shift wOBA to Predict Next Season"
      ],
      "metadata": {
        "id": "L3oFz6J6h5NN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shift wOBA forward to predict next season's performance\n",
        "batting_data[\"next_year_woba\"] = batting_data.groupby(\"player_id\")[\"wOBA\"].shift(-1)\n",
        "\n",
        "# Drop rows where next year's wOBA is NaN (i.e., last recorded season for a player)\n",
        "batting_data = batting_data.dropna(subset=[\"next_year_woba\"])\n",
        "\n",
        "# Ensure year column is integer type\n",
        "batting_data[\"year\"] = batting_data[\"year\"].astype(int)\n",
        "\n",
        "print(\"✅ Successfully Shifted wOBA Forward to Predict Next Season\")\n",
        "print(f\"✅ Dataset Shape After Shift: {batting_data.shape}\")\n",
        "print(batting_data.head())\n"
      ],
      "metadata": {
        "id": "5r-zigj-iGxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create new features"
      ],
      "metadata": {
        "id": "licjQgMNRgJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering: Compute new advanced metrics\n",
        "\n",
        "# BB/K Ratio (Plate Discipline)\n",
        "if \"bb_rate\" in batting_data.columns and \"k_rate\" in batting_data.columns:\n",
        "    batting_data[\"BB_K_Ratio\"] = batting_data[\"bb_rate\"] / batting_data[\"k_rate\"]\n",
        "    print(\"✅ Added BB/K Ratio\")\n",
        "\n",
        "# Speed Influence (Sprint Speed Factor)\n",
        "if \"speed_score\" in batting_data.columns:\n",
        "    batting_data[\"Speed_Impact\"] = batting_data[\"speed_score\"] * batting_data[\"ISO+\"]\n",
        "    print(\"✅ Added Speed-Adjusted ISO\")\n",
        "\n",
        "# Fill missing values\n",
        "batting_data.fillna(0, inplace=True)\n",
        "\n",
        "print(f\"✅ New Features Engineered! Updated Shape: {batting_data.shape}\")\n",
        "\n",
        "# Sort data to ensure correct shifting order\n",
        "batting_data = batting_data.sort_values(by=[\"player_id\", \"year\"])\n",
        "\n",
        "# Compute year-over-year change in wOBA\n",
        "batting_data[\"wOBA_change\"] = batting_data.groupby(\"player_id\")[\"wOBA\"].diff()\n",
        "\n",
        "# Define the weights for rolling wOBA\n",
        "weights_3Y = [0.5, 0.3, 0.2]  # More recent years have higher weight\n",
        "weights_5Y = [0.4, 0.25, 0.15, 0.1, 0.1]\n",
        "\n",
        "def compute_weighted_rolling_wOBA(df, player_col=\"player_id\", year_col=\"year\", woba_col=\"wOBA\"):\n",
        "    \"\"\"\n",
        "    Computes weighted rolling averages for wOBA over 3-year and 5-year windows.\n",
        "    \"\"\"\n",
        "    df = df.sort_values(by=[player_col, year_col])  # Ensure sorting for rolling calculations\n",
        "\n",
        "    # Initialize rolling averages\n",
        "    df[\"weighted_wOBA_3Y\"] = np.nan\n",
        "    df[\"weighted_wOBA_5Y\"] = np.nan\n",
        "\n",
        "    # Process each player separately\n",
        "    for player in df[player_col].unique():\n",
        "        player_mask = df[player_col] == player\n",
        "        player_data = df.loc[player_mask, woba_col]\n",
        "\n",
        "        # Compute 3-Year Weighted Rolling Average\n",
        "        if len(player_data) >= 3:\n",
        "            df.loc[player_mask, \"weighted_wOBA_3Y\"] = (\n",
        "                player_data.rolling(3, min_periods=3)\n",
        "                .apply(lambda x: np.dot(x, weights_3Y[-len(x):]), raw=True)\n",
        "            )\n",
        "\n",
        "        # Compute 5-Year Weighted Rolling Average\n",
        "        if len(player_data) >= 5:\n",
        "            df.loc[player_mask, \"weighted_wOBA_5Y\"] = (\n",
        "                player_data.rolling(5, min_periods=5)\n",
        "                .apply(lambda x: np.dot(x, weights_5Y[-len(x):]), raw=True)\n",
        "            )\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply function to dataset\n",
        "batting_data = compute_weighted_rolling_wOBA(batting_data)\n",
        "\n",
        "# Fill any remaining NaNs with 0\n",
        "batting_data.fillna(0, inplace=True)\n",
        "\n",
        "# Step 2: Implement Age-Based Decline Factor\n",
        "\n",
        "def age_decline_factor(age):\n",
        "    \"\"\"\n",
        "    Models decline after age 30 using a logistic decay function.\n",
        "    Players peak at 27-29, decline past 30.\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp((age - 30) / 3))  # Smooth decline after 30\n",
        "\n",
        "batting_data['age_decline_factor'] = batting_data['Age'].apply(age_decline_factor)\n",
        "\n",
        "# Step 3: Update Feature List\n",
        "batting_features += ['age_decline_factor']\n",
        "\n",
        "batting_data.head()"
      ],
      "metadata": {
        "id": "bd1sYkAiRh_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create League avg features"
      ],
      "metadata": {
        "id": "2rJ7eiTomLfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the stats we want to compare to league averages\n",
        "stats_to_compare = [\"wOBA\", \"ISO\", \"EV\", \"OBP\", \"SLG\", \"hard_hit_rate\", \"max_exit_velocity\"]\n",
        "\n",
        "# Compute league averages per year\n",
        "league_averages = batting_data.groupby(\"year\")[stats_to_compare].mean().reset_index()\n",
        "league_averages.rename(columns={col: f\"league_avg_{col}\" for col in stats_to_compare}, inplace=True)\n",
        "\n",
        "# Merge league averages back into the player data\n",
        "batting_data = batting_data.merge(league_averages, on=\"year\", how=\"left\")\n",
        "\n",
        "for stat in stats_to_compare:\n",
        "    batting_data[f\"rel_{stat}\"] = batting_data[stat] - batting_data[f\"league_avg_{stat}\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "-nKORS8emOKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Create Training Set"
      ],
      "metadata": {
        "id": "peXhVdeKiU-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Updated feature selection (adding newly engineered features)\n",
        "\n",
        "\n",
        "features = [\n",
        "    \"WPA/LI\", \"REW\", \"RE24\", \"xSLG\", \"Off\", \"EV\", \"wRAA\", \"ISO+\",\n",
        "    \"max_exit_velocity\", \"BB_K_Ratio\", \"WPA\", \"Speed_Impact\",\n",
        "    \"rel_wOBA\", \"rel_ISO\", \"rel_EV\", \"rel_OBP\", \"rel_SLG\", \"rel_hard_hit_rate\",\n",
        "    \"Age\", \"wOBA_change\", \"weighted_wOBA_3Y\", \"age_decline_factor\", \"weighted_wOBA_5Y\"\n",
        "]\n",
        "\n",
        "\n",
        "# Define X and y for model training\n",
        "X = batting_data[features]\n",
        "y = batting_data[\"next_year_woba\"]\n",
        "\n",
        "# Fill missing values\n",
        "X = X.fillna(0)\n",
        "y = y.fillna(0)\n",
        "\n",
        "print(f\"✅ Features used: {features}\")\n",
        "print(f\"✅ Training Data Shape: {X.shape}\")\n",
        "\n",
        "# Train-test split (Re-run this before training)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"✅ Train size: {X_train.shape}, Test size: {X_test.shape}\")\n",
        "print(f\"✅ Features used: {features}\")\n"
      ],
      "metadata": {
        "id": "CyKGfqF1iVxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train XGBoost Model"
      ],
      "metadata": {
        "id": "0HDe5t-QibUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    \"n_estimators\": [400, 500, 600],  # Increase estimators slightly\n",
        "    \"max_depth\": [3, 4, 5],  # Increase depth\n",
        "    \"learning_rate\": [0.005, 0.01, 0.02],  # Try slightly higher values\n",
        "    \"subsample\": [0.7, 0.8, 0.9],\n",
        "    \"colsample_bytree\": [0.7, 0.8]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize XGBoost model\n",
        "xgb = XGBRegressor(objective=\"reg:squarederror\")\n",
        "\n",
        "# Grid Search with Cross-Validation\n",
        "grid_search = GridSearchCV(xgb, param_grid, scoring=\"r2\", cv=5, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_xgb = grid_search.best_estimator_\n",
        "\n",
        "# Print best parameters\n",
        "print(f\"🚀 Best Parameters: {grid_search.best_params_}\")\n",
        "\n",
        "# Train best model on full dataset\n",
        "best_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate performance\n",
        "train_score = best_xgb.score(X_train, y_train)\n",
        "test_score = best_xgb.score(X_test, y_test)\n",
        "\n",
        "print(f\"🎯 Optimized Training Score: {train_score:.3f}\")\n",
        "print(f\"📉 Optimized Test Score: {test_score:.3f}\")\n"
      ],
      "metadata": {
        "id": "zzfEHYs_ii6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict Adley's 2024 wOBA using 2023 statistics"
      ],
      "metadata": {
        "id": "HmLP9bgOm0QL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adley Rutschman's FanGraphs ID\n",
        "adley_id = 17621  # Replace with actual ID if different\n",
        "\n",
        "# Filter Adley's 2023 stats\n",
        "adley_2023 = batting_data[(batting_data[\"player_id\"] == adley_id) & (batting_data[\"year\"] == 2023)]\n",
        "\n",
        "# Compute average feature values\n",
        "adley_avg = adley_2023[features].mean().values.reshape(1, -1)\n",
        "\n",
        "# Predict 2024 wOBA\n",
        "predicted_wOBA = best_xgb.predict(adley_avg)[0]\n",
        "\n",
        "print(f\"🎯 Projected wOBA for Adley Rutschman (2024): {predicted_wOBA:.3f}\")\n"
      ],
      "metadata": {
        "id": "TG9IzdZcm55O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Get feature importance from trained XGBoost model\n",
        "importance_df = pd.DataFrame({\n",
        "    \"Feature\": X_train.columns,\n",
        "    \"Importance\": best_xgb.feature_importances_\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=importance_df[\"Importance\"], y=importance_df[\"Feature\"])\n",
        "plt.xlabel(\"Feature Importance Score\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.title(\"Feature Importance in XGBoost Model\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4fWiLpQpQiPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get predictions\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "\n",
        "# Compute residuals\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# Plot residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(residuals, bins=30, kde=True)\n",
        "plt.xlabel(\"Residual (Actual wOBA - Predicted wOBA)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Residual Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ONz2AdzaU2ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify high-error predictions\n",
        "batting_data[\"residuals\"] = y_test - y_pred\n",
        "\n",
        "# Sort by absolute residual error\n",
        "high_residuals = batting_data.loc[X_test.index].copy()\n",
        "high_residuals[\"abs_residuals\"] = high_residuals[\"residuals\"].abs()\n",
        "high_residuals = high_residuals.sort_values(by=\"abs_residuals\", ascending=False)\n",
        "\n",
        "print(\"🔍 Players with Largest Prediction Errors:\")\n",
        "print(high_residuals[[\"player_id\", \"next_year_woba\", \"residuals\"]].head(10))\n"
      ],
      "metadata": {
        "id": "gOo2n8b7VBo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZVf4wS_kfnds"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}